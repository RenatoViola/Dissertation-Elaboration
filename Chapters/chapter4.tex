%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Proposed Solution}
\label{cha:proposed-solution}

\epigraph{
    This chapter describes the proposed system's architecture in some detail, addressing the expected technological stack, the envisioned plan for its development and the methodology for validating the solution. The work plan/schedule is mapped in a Gantt chart.
}{}

\section{Proposal Overview}

Centered around the accessibility of the blind and visually impaired in experiencing visual art, specifically through the use of audio generation techniques, the current dissertation aims to provide an immersive auditory experience through interactive 3D sound environments representative of specific paintings.

The solution we propose consists of a user-friendly 3D soundscape editor for Windows, specifically designed to support the creation and functionality of immersive virtual auditory environments, which are to be made available and interactive through a BVI-accessible mobile application.

Thus, there are two very different although symbiotic parts to this system we aim to develop, one being the de facto editing of 3D sound environments in a desktop application, catered to users without former experience in sound engineering and related software. Just as important, the other part is concerned with the interactivity, functionality and accessibility of said environments in mobile devices operated by BVI individuals. 

The system abstracts the complexities of spatializing sound sources and optimizing accessibility, automatically generating BVI-accessible environments upon export.

Upon implementation, the proposed system will undergo a structured validation process on the two fronts it caters to, through interviews and questionnaires after user testing. The tool itself will be evaluated by individuals with an artistic background and little to no experience in sound design, and testing will focus on its ease-of-use, usability and overall expressiveness. The mobile interaction will be subjected to evaluation by BVI individuals on factors such as ease of navigation, spatial awareness enhancement, level of enjoyment, user preferences and cognitive load assessment.

\subsection{3D Soundscape Editor for Windows}

Inspired by Ferreira’s [ferreira] work on Immerscape (addressed in section 3.4.1), the elaborated tool will feature predefined environments of varying acoustic properties, such as resonance and reverberation, which may be further customized. It is convenient for users that they may easily manipulate and experiment with different sound elements, such as Minecraft’s [minecraft] block-based system, where users can place or erase different types of blocks with distinct functions. 

Thus, the scene is built with a similar block-based system and alike Minecraft’s creative mode, allows for movement in all directions, including free flight. There will be multiple block types, such as: 3D sound emitter, ambient audio, collidable block (only simulates physical barriers, does not emit sound) and user-customized ones. These blocks are editable in several ways, some of which being volume, loop settings, sound file association and object representation. 

Users supply their own sound assets, storing them in a dedicated directory in supported formats (these formats are yet to be decided but are likely to be WAV and/or MP3).

When developing a scene, insights into the end user’s experience are crucial to iteratively improving it. Hence, there are two main modes to the editor: Development Mode, where scenes are built and tailored, and Interactive Mode, where users can test the experience from the point of view of the end-user, though with desktop controls.

Additionally, the user may define default values and boundaries for movement speed, audio cardinality and zoom level in the exported scene, and may also provide a verbal description for the whole piece.

Once a scene is created, it can be saved, loaded, and further edited as needed. Furthermore, a built-in help function will be available at all times, offering a concise explanation of the system’s functionalities.

\subsection{Mobile interaction (APK-based proof of concept)}

The end result of a scene exported from the developed soundscape editor is a top-down 2D representation of the soundscape with large high-contrasting elements representing directional sound sources and collidable zones, making them easier to distinguish within the environment. This is in line with common BVI accessibility practices for visual interfaces in other related studies.

Navigation through the virtual space happens through a joystick control schema, inspired by Nair et al.’s Dungeon Escape game and other mainstream 3D games such as the earliest Resident Evil titles. Spatial position, orientation and proximity to different parts of the artwork are felt through directional audio (implemented through HRTF filters) and dynamic intensity regulation.

The left joystick controls movement, by tilting forward and backward for directional movement and tilting left or right for fixed 15 degree snap rotations complemented by audio cues. The right joystick works as a directional scanner, akin to Nair et al.’s NavStick, where the user can scan the environment in a specific direction and receive a spatially emanated verbal description of the first object within their line of sight, either through text-to-speech or a pre-defined speech output (yet to be defined).

Further, to assist with a more literal interpretation of the environment, double tapping triggers a complete verbal description of the scene (predefined by the environment’s creator) and pauses all other sounds apart from ambient sounds. Obstacles encountered by the user trigger real-time audio feedback in the form of specific collision detection sound cues, once again inspired by Nair et al.’s Dungeon Escape.

Especially in the case of BVI people, cognitive overload is a significant concern. As such, users may control the density of sensory inputs to a degree, by modifying the number of 3D sound sources being played simultaneously using pinch gestures on the touchscreen. Additionally, a long press gesture toggles between sequential and concurrent playing of sounds. In the former mode, sounds are played in a clockwise direction (starting at the closest sound).


\section{Technological Stack}

\section{Work Plan}