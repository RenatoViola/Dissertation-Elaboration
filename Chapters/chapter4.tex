%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Proposed Solution}
\label{cha:proposed-solution}

\epigraph{
  This chapter provides a detailed overview of the proposed system and briefly exposes the solution's validation methodology. It also addresses the expected technological stack and the envisioned plan for the system's development. The work schedule is split into five distinct and concisely explained tasks mapped in a Gantt chart.
}{}

\section{Proposal Overview}

The current dissertation focuses on accessibility for the blind and visually impaired in experiencing visual art, specifically through the use of audio generation techniques. It aims to provide an immersive auditory experience through interactive 3D sound environments representative of specific paintings.

The solution we propose consists of a user-friendly 3D soundscape editor for Windows, specifically designed to support the creation and functionality of immersive virtual auditory environments. These environments will be made available and interactive through a BVI-accessible mobile application.

Thus, this system we aim to develop has two very different symbiotic parts. One is the de facto editing of 3D sound environments in a desktop application, catering to users without previous experience in sound engineering and related software. Just as important, the other part concerns the interactivity, functionality, and accessibility of said environments in mobile devices operated by BVI individuals and is to be experienced with headphones. The system abstracts the complexities of spatializing sound sources and optimizing accessibility, automatically generating BVI-accessible environments upon exportation.

Following the implementation, the proposed system will undergo a structured validation process on the two fronts it caters to through interviews and questionnaires after user testing. The tool will be evaluated by individuals with an artistic background and little to no experience in sound design, and testing will focus on its ease of use, usability, and overall expressiveness. BVI individuals will evaluate mobile interaction based on factors such as ease of navigation, spatial awareness enhancement, level of enjoyment, user preferences, and cognitive load assessment.

\subsection{3D Soundscape Editor for Windows}

Inspired by Ferreira’s~\cite{ferreira2021creating} work on Immerscape (addressed in section~\ref{ssec:immerscape}), the elaborated tool will feature predefined environments of varying acoustic properties, such as resonance and reverberation, which may be further customized. It is convenient for users to easily manipulate and experiment with different sound elements, such as Minecraft ’s~\cite {minecraft} block-based system, where users can place or erase different types of blocks with distinct functions. 

Thus, the scene is built with a similar block-based system and, like Minecraft’s creative mode, allows for movement in all directions, including free flight. There will be multiple block types, such as 3D sound emitter, ambient audio, collidable block (only simulates physical barriers, does not emit sound), and user-customized ones. These blocks are editable in several ways, some of which are volume, loop settings, sound file association, and object representation.

When developing a scene, insights into the end user’s experience are crucial to iteratively improving it. Hence, the editor has two main modes: Development Mode, where scenes are built and tailored, and Interactive Mode, where users can test the experience from the end user's point of view, though with desktop controls.

Additionally, the user may define default values and boundaries for movement speed, audio cardinality, and zoom level in the exported scene and verbally describe the whole piece. Once a scene is created, it can be saved, loaded, and edited. Furthermore, a built-in help function will always be available, offering a concise explanation of the system’s functionalities.

Users supply their sound assets, storing them in a dedicated directory in supported formats (these formats are yet to be decided but are likely to be WAV and/or MP3). On exportation, the editor packages the scene's data (possibly in JSON or XML) and stores it in a designated folder.

\subsection{Mobile Soundscape Player (APK-based proof of concept)}

Loading up a scene exported from the developed soundscape editor and then parsing it, the mobile application displays a top-down 2D representation of the soundscape with large high-contrasting elements representing directional sound sources and collidable zones, making them easier to distinguish within the environment. This aligns with standard BVI accessibility practices for visual interfaces in other related studies~\cite{ahmetovic2021musa,drossos2015accessible,simao2018jogo}.

Navigation through the virtual space happens through a virtual joystick control schema, inspired by Nair et al.’s~\cite{nair2022uncovering} Dungeon Escape game and other mainstream 3D games such as the earliest Resident Evil~\cite{resident-evil} titles. Spatial position, orientation, and proximity to different parts of the artwork are felt through directional audio (implemented through HRTF filters) and dynamic intensity regulation.

The left joystick controls movement by tilting forward and backward for directional movement and tilting left or right for fixed 15-degree snap rotations complemented by audio cues. The right joystick works as a directional scanner, akin to Nair et al.’s~\cite{nair2021navstick} NavStick, where the user can scan the environment in a specific direction and receive a spatially emanated verbal description of the first object within their line of sight, through a predefined speech output.

Further, to assist with a more literal interpretation of the environment, double tapping triggers a complete verbal description of the scene (predefined by the environment’s creator) and pauses all other sounds apart from ambient sounds. Obstacles the user encounters trigger real-time audio feedback in the form of specific collision detection sound cues, once again inspired by Nair et al.’s~\cite{nair2022uncovering} Dungeon Escape.

Especially for BVI people, cognitive overload is a significant concern~\cite{guerreiro2023design,nair2022uncovering}. As such, users may control the density of sensory inputs to a degree by modifying the number of 3D sound sources being played simultaneously using pinch gestures on the touchscreen. Additionally, a long press gesture toggles between sequential and concurrent playing of sounds. In the former mode, sounds are played in a clockwise direction (starting at the closest sound).


\section{Technological Stack}

We selected the Unity~\cite{unity} game engine as the primary development environment for the desktop soundscape editor and mobile application prototype. One factor that solidified this choice was its adoption among some of the most relevant related work we have analyzed~\cite{ferreira2021creating,guerreiro2023design,nair2021navstick,nair2022uncovering,simao2018jogo,yang2019audio} in chapter~\ref{cha:related-work}.

A real-time 3D development platform, while Unity~\cite{unity} is mainly known for its role in game development, its versatility has led to widespread use in all sorts of interactive 2D and 3D experiences across various industries~\cite{techical-overview-unity,unity,what-is-unity}. It provides extensive cross-platform build support, including the hardware we are particularly interested in: Windows PC (for the editor application) and Android (for the mobile interaction).

Aside from its powerful rendering capabilities, Unity~\cite{unity} sports strong community support, a vast amount of learning resources, and a convenient package manager extending its functionality with third-party libraries. Its learning curve is also friendlier than other mainstream 3D game engines like Unreal Engine~\cite{unreal-engine}.

With a built-in 3D audio system, Unity~\cite{unity} provides a solid foundation for basic sound spatialization with distance attenuation according to positioning, a spatial blend parameter, and adjustable volume roll of, among some other settings. While it may be adequate for rudimentary 3D audio, this built-in system is limited, lacking binaural rendering and other relevant capabilities. Fortunately, specialized plugins for advanced spatial audio address the vanilla system’s limitations by adding some of the essential and advanced spatialization functionalities it lacks.

Initially, we had considered the Google Resonance Audio SDK~\cite{resonance-audio} for integration within Unity~\cite{unity}, as it offered relevant features such as HRTF processing and environmental modeling. Furthermore, some of the analyzed studies~\cite{ferreira2021creating,simao2018jogo,yang2019audio} had successfully incorporated this library in their Unity-based environment. However, it has been deprecated for quite some time and has no support for recent versions of the Unity~\cite{unity} engine.

For these reasons, we turned to the Steam Audio~\cite{steam-audio} framework instead, which has been actively maintained, well-documented, and compatible with Unity~\cite{unity} engine updates. Moreover, we were motivated by the use of this toolkit in NavStick~\cite{nair2021navstick} and Dungeon Escape~\cite{nair2022uncovering}, two of the most influential works for our proposal. Supposedly easy to implement and deploy, Steam Audio~\cite{steam-audio} encompasses high-fidelity HRTF-based binaural rendering and geometry-based occlusion, reflection, and reverberation effects, among other spatial features contributing to natural sounding immersion.



\section{Work Plan}

To adequately manage and organize the work to be developed throughout this dissertation, the proposed solution’s implementation will constitute five distinct stages of development, each representing a relevant milestone:
\begin{itemize}
  \item \textbf{Initial Research \& Concept Refinement:} Initially, some time will be reserved to develop simple conceptual mockups of both the desktop editor and the mobile prototype, showcasing their key functionalities and accessibility considerations. These will then be presented to supposed end-users, such as non-experts in sound design and BVI individuals. The feedback gathered will assess whether the currently proposed feature set is adequate for the audience’s needs and ultimately refine it.
  \item \textbf{Soundscape Editor (PC) – Development:} Upon finalizing the architecture details for both applications based on user feedback and confirming what technologies will be utilized, the focus will shift onto the editor’s core development. Such will mainly involve integrating advanced spatial audio with the Steam Audio~\cite{steam-audio} framework and implementing movement alongside an expressive block-based system. Other subtasks include developing a simple UI for adjustable settings, scene creation, editing, and erasure. Since the proposed interactive mode emulates mobile interaction, it will likely be developed alongside it. 
  \item \textbf{Mobile Interactive Prototype  – Development:} The design of the mobile interaction’s accessible map view parsed out of a previously editor-generated scene will be the first subtask under focus. Immediately after comes the joystick-based navigation, assisted with snap rotation and directional scanning. Finally, spatialized audio feedback and collision detection will be integrated alongside the ability to toggle between sequential and concurrent stimuli, adjusting audio cardinality and triggering the scene’s verbal description.
  \item \textbf{Results and System Evaluation:} Before proceeding with evaluation, we will take the time to thoroughly test both parts of the developed system and debug it where needed. We will then define an adequate methodology for evaluating each part of the solution, catering to its specific end-user demographic. Having established the evaluation methodology to apply, user tests with the targeted audiences will be conducted. The gained insights will be used to assess the system’s quality both in usability and accessibility.
  \item \textbf{Dissertation Writing \& Revisions:} The dissertation document will be written in parallel with some of the aforementioned tasks and will mainly incorporate the implementation details and evaluation results into the discussion. Additionally, previously written chapters may be revisited and refactored where needed.
 \end{itemize}

The following chart (Figure~\ref{fig:work-plan-img}) exposes the expected duration of each of the tasks defined in the proposed work plan.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{work-plan}
    \caption{Gantt chart displaying the proposed work distribution over the remaining months.}
    \label{fig:work-plan-img}
  \end{figure}