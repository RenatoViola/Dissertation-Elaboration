%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Proposed Solution}
\label{cha:proposed-solution}

\epigraph{
  This chapter provides a detailed overview of the proposed system and briefly exposes the solution's validation methodology. It also addresses the expected technological stack and the envisioned plan for the system's development. The work schedule is split into five distinct and concisely explained tasks mapped in a Gantt chart.
}{}

\section{Proposal Overview}

The solution we propose consists of a user-friendly \gls{3D} soundscape editor for Windows, specifically designed to support the creation and functionality of immersive virtual auditory environments. These environments will be made available and interactive through a BVI-accessible mobile application, given the widespread use of smartphones. With this approach, we intend to enable curators to generate immersive \gls{3D} audio environments representative of specific paintings, and to have \gls{BVI} users explore these environments interactively. Figure~\ref{fig:concept-img} attempts to illustrate the intended approach from a purely conceptual standpoint.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1.0\linewidth]{concept-cropped}
  \caption{Concept representation. Image is \textit{O Bosque Sagrado} by Maria Benamor, 1975. Collection of Museu Nacional Gr\~ao Vasco. (Adapted from~\cite{o-bosque-sagrado}).}
  \label{fig:concept-img}
\end{figure}

Thus, the system we aim to develop has two very different symbiotic parts. The first is the de facto editing of \gls{3D} sound environments in a desktop application, catering to curators without previous experience in sound engineering and related software. It abstracts the complexities of spatializing sound sources and optimizing accessibility, automatically generating BVI-accessible environments upon exportation. Furthermore, it features two toggleable modes, one for development and the second for testing. Just as important, the other part consists of a mobile application where the previously generated scenes are made available for interaction. It concerns the interactivity, functionality, and accessibility of said environments for \gls{BVI} individuals, on a mobile device.

Following the implementation, the proposed system will undergo a structured validation process on the two fronts it caters to through user testing, employing a subjective quality inference mechanism. Through Likert scale surveys and qualitative feedback, the editor tool will be evaluated by individuals with an artistic background and no experience in sound design, to whom testing will focus on ease of use and overall expressiveness. Analogously, \gls{BVI} individuals will evaluate mobile interaction based on factors such as ease of navigation, spatial awareness enhancement, level of enjoyment, user preferences, and cognitive load assessment.

\subsection{Mobile Soundscape Player}

Loading up a scene exported from the developed soundscape editor and then parsing it, the mobile application will display a top-down \gls{2D} representation of the soundscape with large high-contrasting elements representing directional sound sources and collidable zones, making them easier to distinguish within the environment. This aligns with standard \gls{BVI} accessibility practices for visual interfaces in other related studies~\cite{ahmetovic2021musa,drossos2015accessible,simao2018jogo}.

Navigation through the virtual space happens through a virtual joystick control schema, inspired by Nair et al.’s~\cite{nair2022uncovering} Dungeon Escape game and other mainstream \gls{3D} games such as the earliest Resident Evil\footnote{https://game.capcom.com/residentevil/en/} titles. Spatial position, orientation, and proximity to different parts of the artwork are felt through directional audio (implemented through \gls{HRTF} filters) and dynamic intensity regulation.

The left joystick will control movement by tilting forward and backward for directional movement and tilting left or right for fixed 15-degree snap rotations complemented by audio cues. The right joystick will work as a directional scanner, akin to Nair et al.’s~\cite{nair2021navstick} NavStick, where the user can scan the environment in a specific direction and receive a spatially emanated verbal description of the first object within their line of sight, through a predefined speech output.

Further, to assist with a more literal interpretation of the environment, double tapping will trigger a complete verbal description of the scene (predefined by the environment’s creator) and pause all other sounds apart from ambient sounds. Obstacles encountering the user will trigger real-time audio feedback in the form of specific collision detection sound cues, once again inspired by Nair et al.’s~\cite{nair2022uncovering} Dungeon Escape.

Especially for \gls{BVI} people, cognitive overload is a significant concern~\cite{guerreiro2023design,nair2022uncovering}. As such, users may control the density of sensory inputs to a degree by modifying the number of \gls{3D} sound sources being played simultaneously using pinch gestures on the touchscreen. Additionally, a long press gesture toggles between sequential and concurrent playing of sounds. In the former mode, sounds are played in a clockwise direction (starting at the closest sound).


\subsection{Soundscape Editor for Windows}

Inspired by Ferreira’s~\cite{ferreira2021creating} work on Immerscape (addressed in section~\ref{ssec:immerscape}), the editing tool to be developed will feature predefined environments of varying acoustic properties, such as resonance and reverberation, which may be further customized. 

It is convenient for users to easily manipulate and experiment with different sound elements, such as Minecraft\footnote{https://www.minecraft.net/en-us}’s block-based system, where users can place or erase different types of blocks with distinct functions. Thus, the scene is built with a similar block-based system and, like Minecraft’s creative mode, allows for movement in all directions, including free flight. There will be multiple block types, such as \gls{3D} sound emitter, ambient audio, collidable block (only simulates physical barriers, does not emit sound), and user-customized ones. These blocks are editable in several ways, some of which are volume, loop settings, sound file association, and object representation.

When developing a scene, insights into the end user’s experience are crucial to iteratively improving it. Hence, the editor will have two main modes: Development Mode, where scenes are built and tailored, and Interactive Mode, where users can test the experience from the end user's point of view, though with desktop controls.

Additionally, the user may define default values and boundaries for movement speed, audio cardinality, and zoom level in the exported scene and verbally describe the whole piece. Once a scene is created, it can be saved, loaded, and edited. Furthermore, a built-in help function will always be available, offering a concise explanation of the system’s functionalities. Users will supply their sound assets, storing them in a dedicated directory in supported formats (these formats are yet to be decided but are likely to be WAV and/or MP3). On exportation, the editor will package the scene's data (possibly in JSON or XML) and store it in a designated folder.


\section{Technological Stack}

We selected the Unity game engine as the primary development environment for the desktop soundscape editor and mobile application prototype. One factor that solidified this choice was its adoption among some of the most relevant related work we have analyzed~\cite{ferreira2021creating,guerreiro2023design,nair2021navstick,nair2022uncovering,simao2018jogo,yang2019audio} in chapter~\ref{cha:related-work}.

A real-time \gls{3D} development platform, while Unity is mainly known for its role in game development, its versatility has led to widespread use in all sorts of interactive \gls{2D} and \gls{3D} experiences across various industries~\cite{techical-overview-unity,what-is-unity}. It provides extensive cross-platform build support, including the hardware we are particularly interested in: Windows PC (for the editor application) and Android (for the mobile interaction).

Aside from its powerful rendering capabilities, Unity sports strong community support, a vast amount of learning resources, and a convenient package manager extending its functionality with third-party libraries. Its learning curve is also friendlier than other mainstream \gls{3D} game engines like Unreal Engine.

With a built-in \gls{3D} audio system, Unity provides a solid foundation for basic sound spatialization with distance attenuation according to positioning, a spatial blend parameter, and adjustable volume roll of, among some other settings. While it may be adequate for rudimentary \gls{3D} audio, this built-in system is limited, lacking binaural rendering and other relevant capabilities. Fortunately, specialized plugins for advanced spatial audio address the vanilla system’s limitations by adding some of the essential and advanced spatialization functionalities it lacks.

Initially, we had considered the Google Resonance Audio SDK for integration within Unity, as it offered relevant features such as \gls{HRTF} processing and environmental modeling. Furthermore, some of the analyzed studies~\cite{ferreira2021creating,simao2018jogo,yang2019audio} had successfully incorporated this library in their Unity-based environment. However, it has been deprecated for quite some time and has no support for recent versions of the Unity engine.

For these reasons, we turned to the Steam Audio framework instead, which has been actively maintained, well-documented, and compatible with Unity engine updates. Moreover, we were motivated by the use of this toolkit in NavStick~\cite{nair2021navstick} and Dungeon Escape~\cite{nair2022uncovering}, two of the most influential works for our proposal. Supposedly easy to implement and deploy, Steam Audio encompasses high-fidelity HRTF-based binaural rendering and geometry-based occlusion, reflection, and reverberation effects, among other spatial features contributing to natural sounding immersion. While the specific library to which its default \gls{HRTF} dataset belongs is not explicitly stated in official documentation, some online discussions suggest it may be based on Phonon\footnote{https://www.impulsonic.com/what-is-trueaudio-phonon/}.


\section{Implementation}

\subsection{Mobile BVI-Acessible Soundscape Player Prototype}

\lipsum[1-5]

\subsection{Desktop Beginner-Friendly Soundscape Editor}

\lipsum[1-5]

\section{Initial Research \& Concept Refinement}

Prior to the system's technical implementation, conceptual designs of the mobile soundscape player and the desktop editor were produced in Figma, illustrating the key functionalities envisioned for each application. At this stage, the mobile application was identified as the main component to prove the concept, since it would directly serve BVI users.

The first implementation efforts therefore focused on an early version of the mobile prototype, already including most of the features described in section 4.1.1. This build was sufficient to demonstrate the feasibility of the proposed concept for accessible and interactive interpretation of a painting, as was ultimately intended. However, compared to the final application it lacked ambient sound regulation, the proximity sensor, and haptic feedback, among several other adjustments - as these hadn't yet been planned at the time. Along with the Figma mockups of the desktop editor, some of the mobile functionalities were presented in a remote meeting with researchers from the Department of Conservation and Restoration of NOVA School of Science and Technology. The researchers saw potential in the idea and expressed interest in its evolution.

The most important stage of this early phase came in late May, when the mobile prototype was tested on-site at the Raquel e Martin Sain Foundation - a social solidarity institution dedicated to the professional education and social integration of BVI individuals. Two blind participants volunteered their time: Cláudia Pires, a student at the foundation, and Ana Inês Colares, one of its instructors. Both of these interviews followed a simplified protocol with similarities to that of the final study but with less specific tasks and more open-ended questions, for the goal was refinement rather than evaluation. The painting "O Bosque Sagrado" by Maria Benamor was used as the painting for the test scenario, also being used in the final study of the application (section~\ref{sec:mobile-sonic-painting-exploration}).

The first interviewee, Cláudia Pires, pointed to several areas for improvement in the experience. She felt that ambient sound should be lower and that the sound effects used for movement and rotation were too similar, sometimes hard to distinguish. Though she could discern sound direction clearly, perceiving proximity to the sound sources was more difficult. While she found the directional scanner useful, she noted that it required alignment that was much too precise, with narrations cutting off if not perfectly targeted. Cláudia also reported little difference between sequential and simultaneous reproduction modes and sometimes had difficulty tracking how many sounds were active. The clock hour orientation feature was very helpful to her but she stated that it should have been introduced earlier in the protocol. Finally, she strongly preferred the console scheme over the touch gestures, suggesting haptic feedback and larger virtual joysticks as possible improvements to touch usability.

Many of the points brought up by Cláudia were echoed by the second interviewee, Ana Inês Colares, who also provided further insights. Accentuating the importance of the clock hour orientation system, she too felt that this feature should be introduced in an earlier task. Ana Inês suggested that sound sources should increase in volume more noticeably when approached and that ambient sound should be toggleable, as it could distract from the other elements at times. Like Cláudia, she noticed little difference between the two reproduction modes and found sound source direction easier to perceive than proximity, occasionally struggling to locate specific sounds in the environment. She also preferred the console controls and noted the difficulty of touch gestures and especially virtual joysticks without haptic feedback. Lastly, she proposed the addition of a menu to allow switching between different soundscapes, if the application were to support several painting representations. Most importantly, from the conversation with Ana Inês and her emphasis on the amplification of sound according to proximity, derived the idea for the currently implemented proximity sensor.

The purpose of this early study was to garner real input from the individuals to whom the application was intended, and in this way assess whether the proposed features were indeed adequate for BVI needs, rather than only in theory. These preliminary interviews were fundamental in shaping the application into what it eventually became, as both participants provided detailed feedback which revealed not only the prototype's shortcomings but also some of its strengths. As much as possible, their suggestions were incorporated into the application's final design and in the later evaluation (section~\ref{ssec:mobile-results-overview}) these proved both practical and meaningful.