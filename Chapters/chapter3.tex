%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter3.tex
%% NOVA thesis document file
%%
%% Chapter with a short latex tutorial and examples
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter3.tex}%

\makeatletter
\newcommand{\ntifpkgloaded}{%
  \@ifpackageloaded%
}
\makeatother


\chapter{Related Work}
\label{cha:related-work}

% epigraph configuration
\epigraphfontsize{\small\itshape}
\setlength\epigraphwidth{12.5cm}
\setlength\epigraphrule{0pt}

\epigraph{
  This chapter reviews relevant research and applications related to the topic, including technologies and approaches that have been used to address accessibility for visually impaired individuals. It identifies existing gaps and highlights the unique aspects of the proposed solution in comparison to current state-of-the-art techniques, as well as some similarities.
}{}

\section{Immersive Audio Experiences in Cultural Environments}

Audio is a widely used vehicle for delivering immersive experiences in cultural environments. The following two studies exemplify this statement, and are centered around spatial audio, since it is a central theme to this dissertation. 

Focused on recreating the city of Évora’s culturally rich historical soundscapes, Ferreira~\cite{ferreira2021creating} created Immerscape, a tool aimed at non-expert users for generating 3D audio scenes, utilizing HRTFs to spatialize sound. We cover Immerscape in further detail in subsection~\ref{ssec:immerscape}. Kabisch et al.~\cite{kabisch2005sonic} used motion tracking, image analysis and sonification alongside real-time directional sound to integrate panoramic visual landscapes with spatialized audio, presenting such research in an interactive art exhibit.

\subsection{Eyes-Free Art}

Looking to enhance the accessibility of visual art to BVI individuals and go beyond the shortcomings of the typical audio descriptions or guides, Rector et al.~\cite{rector2017eyes} designed “Eyes-Free Art”, a novel approach to sonically interacting with 2D art, aiming to be both aesthetically stimulating and engaging. 

It is in essence, a carefully crafted proxemic audio interface that, mirroring the conventional intuition of visual proxemic interfaces, renders more detail as proximity to the piece increases. To define such proximity, a Microsoft Kinect device was used to track the user’s position and movements, not only to determine the user’s distance to the painting but also if it is facing towards it. The audio interpretation a user hears varies according to the proxemic zone in which it finds itself, of which there are four distinct and equally sized ones (Figure~\ref{fig:eyes-free-art-img}). Upon entering any zone, the user is verbally alerted to where it is and may continue moving between zones, spending as much time as it wants in each.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{eyes-free-art}
  \caption{The four zones of the Eyes-Free Art proxemical interface. Image is \textit{The Blue Rider} from Wassily Kandinsky (Reproduced from~\cite{rector2017eyes}). \copyright~2017 Copyright held by the owner/author(s).}
  \label{fig:eyes-free-art-img}
\end{figure}

The furthest zone consists only of background music used to set the mood of the piece. It is followed by a sonification area aimed at communicating the painting’s chromatic diversity through musical features. The second-closest zone, sound effects, highlights the painting’s literal aspects such as the type of objects and their spatial correlation. The final and most detailed of zones consists of a manually curated verbal description. 

Some initial interviews were conducted, from which Rector et al. noted the importance of using commodity technology (promoting control and independence) and including both the literal and subjective aspects of a painting.

A final evaluation with 13 BVI participants attested to the success of this implementation, as patrons felt immersed and had a rich experience interpreting the art work.

Eyes-Free Art resonates with the current dissertation in several ways. Most importantly, in its integration of zones of differing detail according to proximity, allowing users to explore at their own pace and at their desired level of detail, closely aligning with our goal of promoting independence and interactivity. Furthermore, it also addresses the mapping of visual elements to sound, though the current work focuses on spatial audio rather than sonification.


\subsection{Audio-augmented museum experiences with gaze tracking}

Aiming to enrich the perception of landscape and genre paintings, Yang et al.~\cite{yang2019audio} track a visitor’s gaze and spatialize sounds for drawn objects and scenes within the paintings. Personalizing the audio output based on the user’s gaze, the system amplifies the sounds directed at the viewers focal point, attenuating the rest. 

Gaze and pose tracking required an eye-tracker and a connected laptop in a backpack. Additionally, headphones were used for spatial audio playback (Figure~\ref{fig:gaze-img}). The propagation of sound was dynamically simulated according to a user’s gaze and pose via the Google Resonance Audio SDK, while the Unity3D game engine was employed to model the room and map the various sound sources.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{gaze-1}
  \caption{Two of the paintings used in the application. Blue audio icons represent virtual sounds accurately spatialized relative to the user (b). (Adapted from~\cite{yang2019audio}). \copyright~2019 Copyright held by the owner/author(s).}
  \label{fig:gaze-img}
\end{figure}

A user study with 14 young adults revealed some challenges regarding the consistency of the eye-tracking and differences in preference across individuals, such as the amplification of sound and the smoothness of its adjustment. The experience was still positively received overall, as it helped most users focus on areas of interest, some even feeling guided by their gaze.

While gaze tracking proves itself a mostly intuitive approach to dynamic audio spatialization and interactivity with an artwork, it is not the most appropriate technique in the context of our work, which focuses on BVI users.

Nonetheless, this study provides valuable insights to our own. Akin to our proposal’s proximity-based 3D audio, it narrates a painting’s visual elements by spatially embedding sounds to specific points of interest and dynamically adjusting their intensities. Furthermore, there is relevance in learning from the challenges highlighted by Yang et al., namely in ensuring smooth audio transitions, responsiveness and accommodating for some degree of personal preference, through personalization.


\section{Accessibility in Auditory Representations of Art and Virtual Environments}

Multisensory experiences have been shown to have potential in improving accessibility and independence for the blind and visually impaired, by providing alternative ways of perceiving content considered to be visual in essence.

Li~\cite{li2024beyond} developed an audio-only inclusive prototype for navigating AR content without having to rely on visual cues, by incorporating spatialized audio to provide intuitive feedback on object proximity and spatial relationships. Meanwhile, Cavazos Quero et al.~\cite{cavazos2021accessible} implemented a touch-sensitive multimodal guide providing localized audio descriptions based on touch, promoting independence in both the exploration and interpretation of artworks. Banf and Blanz~\cite{banf2013sonification} presented a system using touchscreens that actively promotes a visually impaired user to explore an image and receive audio feedback corresponding to its local content. Such was achieved by employing computer vision and machine learning algorithms to sonify images from low to a high level.

\subsection{Navmol}

Navmol~\cite{fartaria2013navmol} is a molecular browser and editor specifically designed for blind and visually impaired users, aiming to provide BVI accessibility in the higher education of chemistry. 

Via a speech synthesizer, it provides an auditory portrayal of the atomic composition of complex molecular structures. Such configurations are bidimensionally depicted using the analogue clock metaphor, consisting of mapping directions to the positions of a clock and well known among the BVI community. As some users retain some degree of sight, the program has a simple graphical interface (Figure~\ref{fig:navmol-img}) with them in mind, visually displaying the selected atoms and some molecular contours.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{navmol}
  \caption{Navmol's clock system, where carbon-3 has neighbors at 6 o'clock and 10 o'clock, respectively carbon-4 and carbon-2 (Adapted from~\cite{fartaria2013navmol}).}
  \label{fig:navmol-img}
\end{figure}

Rodrigues~\cite{rodrigues2015navmol} merged the simple clock analogy with the application of HRTFs on the auditory signal generated by the existing Navmol program at the time (version 2.0), in order to create realistic directional sound cues, perceived to derive from where the atom is positioned. Usability tests demonstrated the efficacy of this integration, with users achieving an average task accuracy of 95.7\% in identifying and navigating molecular structures.

Knowing that HRTF performance may greatly vary across users due to inter-individual differences in morphology, Rodrigues conducted a study on the performance of 53 distinct HRTF measurements. It confirmed a significant variation in performance across different HRTF datasets for individual users. The five most consistently well performing measurements – KEMAR, CIAIR, IRC05, IRC25 and IRC44, were then selected for use in one additional study, motivated by the significant variation in performance across different HRTF datasets for individual users. The necessity to allow users to select their preferred HRTF dataset was made apparent and Navmol was updated accordingly.

Rodrigues’ work very much aligns with the goals of this dissertation, as it highlights not only the efficacy of spatial audio (integrated through HRTFs) in the perception of spatial and structural information but also addresses the suitability (or lack thereof) of specific HRTFs to distinct users, allowing them to tailor their own experience to a degree.


\subsection{MusA}

Ahmetovic et al.~\cite{ahmetovic2021musa} proposed MusA intending to address the limitations of traditional artwork accessibility methods, such as audio guides. MusA is a mobile application that leverages AR to provide interactive and accessible descriptions of paintings to low vision visitors. These descriptions are structured into chapters, each representing a specific area of the artwork, and are linked to an image overlaid on the artwork with a contour highlighting the described section.

The application features artwork recognition via the mobile’s camera, interactive navigation across chapters, and touch-based overlays. It was specifically designed for users with some residual sight, presenting a clutter-free and to the point interface (Figure~\ref{fig:musa-img}) compatible with system magnifiers, enlarged fonts and adjustable contrast filters.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{musa}
  \caption{Some screens of the MusA app. The first two screens respectively correspond to chapter navigation and selection in its first iteration. The third screen corresponds to the second iteration's virtual mode (Adapted from~\cite{ahmetovic2021musa}). \copyright~2021 Copyright held by the owner/author(s).}
  \label{fig:musa-img}
\end{figure}

After an initial user testing with LV participants identifying some challenges, a second and final iteration of the app incorporated audio and haptic feedback, higher contrast contours, and a zoom-supportant virtual mode designed to replace AR in case the user can’t frame the painting continuously. 

User studies revealed MusA to be a significantly more engaging and user-friendly experience than a traditional audio guide, promoting freedom in exploration. Despite some issues in overlay clarity, MusA was effective in supporting the needs of low-vision people, and they were pleased by the ability to use the app at home and in their own device.

The work of Ahmetovic et al. parallels that of this dissertation in certain aspects, as alike the chapter navigation available in MusA, the proposed interactive soundscape will offer users control over what details they wish to explore and focus on specific features of the artwork, only with proximity-based or gyroscopic interactions. Their findings show that even for low vision users, visual feedback through properly contrasting overlays enriches the perception of a painting’s structure and details. As such, we mustn’t undervalue visual cues and should ensure low visual clutter alongside proper visibility settings, such as contrast and font size.



\section{Leisurely and BVI Inclusive Applications}

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui. Etiam rhoncus. Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel, luctus pulvinar, hendrerit id, lorem. Maecenas nec odio et ante tincidunt tempus. Donec vitae sapien ut libero venenatis faucibus. Nullam quis ante. Etiam sit amet orci eget eros faucibus tincidunt. Duis leo. Sed fringilla mauris sit amet nibh. Donec sodales sagittis magna. Sed consequat, leo eget bibendum sodales, augue velit cursus nunc,

\subsection{LEAP Tic-Tac-Toe}

Drossos et al.~\cite{drossos2015accessible} adapted an audio-only version of Tic-Tac-Toe to be made both appealing and accessible to visually impaired children, by empowering it with sonic displays.

Simple as it is, Tic-Tac-Toe is a visually reliant game and spatial perception alongside game state, positioning and rules all posed a significant challenge when designing it to be BVI accessible. Additionally, people with residual vision must also be accounted for, enabling them to complement their auditory experience with their remaining vision.

To this end, they designed and implemented not only the game itself but also a custom game engine and audio engine specifically intended at the effective development of audio games accessible to the visually impaired. Within the game world represented by the game engine, static objects are the most common type of game object, in which sound objects are included.

Carefully ensuring that BVI auditory needs were met, Drossos et al. categorized sound objects into three types that when collectively employed, enable the development of any stage, be it simple or complex. These are classified as: Standard (no interaction with the game, ambient soundtrack is an example), Interruptible (sounds that provide little more than redundant or aesthetic information) and Blocking (sounds carrying important information requiring special attention, interruptible sounds are discarded).

The audio engine functions as the API serving the audio to these objects and handles the sound settings as well as the sonic display implementation. Auditory icons (recognizable real-world sounds) and earcons (synthesic sounds) are used for game state awareness while binaural processing (utilizing the KEMAR HRTF library) is used for conveying spatial details.

The game’s GUI is simple and employs intense contrast alongside large optical elements (Figure~\ref{fig:tic-tac-toe-img}), accomodating for users with residual sight. The auditory interface provides constant feedback of the effects for every action and players sense direction and three-dimensionality through the localized sound cues. In addition, there are pre-recorded audio instructions for each game component.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\linewidth]{tic-tac-toe}
  \caption{Part of the Tic-Tac-Toe game's graphical user interface (Adapted from~\cite{drossos2015accessible}). \copyright~2015 ACM.}
  \label{fig:tic-tac-toe-img}
\end{figure}

In user studies, visually impaired children received the game very positively, though many were experiencing an accessible game for the first time.

Drossos et al.’s findings are of value for this dissertation as they address challenges we will inevitably come across such as the need for constant, concurrent and discernible audio feedback, as well as conveying localization information through the sounds in order for users to navigate themselves around the soundscape. Additionally, they also address relevant limitations as in not all sounds being equally effective for spatial localization and the varying spatial awareness among users.


\subsection{The Preferred Spatial Awareness Tools for BVI People In Video Games}

While the minimap is one of the most employed spatial awareness tools (SATs) in video games, crucial even for sighted players in learning the layout of their surroundings, it still has no successful equivalent in regards to BVI accessibility. 

Attempting to bridge this gap in acessibility, Nair et al.~\cite{nair2021towards} took it upon themselves to tackle the creation of a universal and acoustic BVI-friendly minimap, or more concretely, uncovering the most relevant design factors as well as the merits and limitations of the best acoustic techniques to do so.

Two main questions were at the center of their study, the first regarding the key aspects of spatial awareness valued the most by visually impaired players in games, and the second focusing on the effectiveness of current SATs in supporting said aspects.

Intending to delve into both, Nair et al.~\cite{nair2022uncovering} investigate the design of the four leading SATs (Figure~\ref{fig:dungeon-escape-img}) in enhancing spatial perception for the visually impaired in a 3D game world, vastly different approaches developed in previous research. These being the: 
\begin{itemize}
  \item \textit{Smartphone Map -} A touchscreen map working in tandem with the game to provide spatial information through sound effects and text-to-speech
  \item \textit{Whole-Room Shockwave –} When triggered, emits 3D sounds from certain objects based on their distance, simulating a refined and customizable echolocation
  \item \textit{Directional Scanner –} Allows players to survey a surrounding direction by tilting the right thumbstick towards it, announcing the first object in line-of-sight with directional sound
  \item \textit{Simple Audio Menu –} Lists the points of interest in a room through their corresponding sounds effects and text-to-speech, in alphabetical order
\end{itemize}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{dungeon-escape}
  \caption{The four spatial awareness tools implemented within Dungeon Escape~\cite{nair2022uncovering}). \copyright~2022 ACM.}
  \label{fig:dungeon-escape-img}
\end{figure}

To evaluate the effectiveness of each of these approaches in conveying the most essential aspects of spatial awareness and address the two main questions of the research, Nair et al. implemented them all into Dungeon Escape, an original third person 3D game in which the players were required to use the given SATs to gain enough spatial awareness to succeed. 

Implemented in the Unity game engine, Dungeon Escape is an adventure game specifically designed for the study and consists in players navigating dungeons in search of objects that allow them to overcome obstacles and thus escape the dungeons. 

Despite its focus being on studying the performance of the SATs within the differing dungeon layouts, it is more than a simple playground for the different SATs, portraying itself as an accessible game in other ways. As in well known 3D games, the left thumbstick is used for movement and rotation, and in this case aided by an utility mimicking snap rotation. Collisions have an unique sound effect and relevant sound plays from any object within a 2-meter radius of the player. Furthermore, players can lock onto objects of interest by placing a looping audio beacon on them.

Following a user study with 9 participants, of which eight were completely blind, the most critical aspect of spatial awareness was found to be position and orientation. Presence, arrangement and adjacent areas were tied for second place, whilst shape and scale overwhelmingly came last. 

One of the key findings was that despite the importance of position and orientation, none of the approaches were fully satisfactory, though the directional scanner performed the best. One other relevant takeaway was the effectiveness of combining some of the SATs, with the greatest spatial awareness being provided by the directional scanner and simple audio menu combination. Finally, visually impaired individuals greatly value customizable SATs, as the aforementioned SAT combination was closely followed by the combination of the directional scanner and whole-room shockwave. This is despite the whole-room shockwave having been considered overwhelming in several instances (yet costumizable), and the simple audio menu a great way to communicate presence (yet disliked by half the participants for being “spoilery”).

Nair et al.’s research provides several insights to the current dissertation mostly by exposing the strengths and weaknesses of the different SATs but also in the accessible design of Dungeon Escape. Most importantly, it highlights the importance of position and orientation for proper spatial understanding and exploration, which we will prioritize conveying in our work, possibly by incorporating combinations of the most synergetic SATs as was done in their study. Additionally, it touches on how users may be overwhelmed by too much detail, inspiring us to focus on providing cues qualitively rather than quantitively.





\section{Tools for Soundscape Creation}

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui. Etiam rhoncus. Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel, luctus pulvinar, hendrerit id, lorem. Maecenas nec odio et ante tincidunt tempus. Donec vitae sapien ut libero venenatis faucibus. Nullam quis ante. Etiam sit amet orci eget eros faucibus tincidunt. Duis leo. Sed fringilla mauris sit amet nibh. Donec sodales sagittis magna. Sed consequat, leo eget bibendum sodales, augue velit cursus nunc,

\subsection{Immerscape}
\label{ssec:immerscape}

Contributing to the PASEV project, focused on retaining and promoting the city of Évora’s cultural patrimony, namely the rich soundscapes correspondent to the various historical events which took place between 1540 and 1910, Ferreira~\cite{ferreira2021creating} proposed Immerscape.

Intended to provide the PASEV projects’s team with the means to reconstruct the city’s auditory history from current sound recordings, Immerscape is a soundscape editing tool accessible even to those without prior experience in programming or sound composition software, allowing for the creation of historical soundscapes out of previously collected recordings and the generation of immersive 3D audio files representing such soundscapes, while abstracting away the technical details behind spatial audio generation.

The editor itself was implemented within the Unity game engine and the acoustic immersion leveraged the Google Resonance Audio SDK to spatialize sound through the application of HRTF filters, requiring the use of headphones to be properly evaluated. 

Besides an accessible interface with minimal complexity (Figure~\ref{fig:immerscape-img}), Ferreira defined some fundamental requirements for Immerscape such as the ability to select predefined 3D sound environments (with unique resonance and reverb properties), immersive environmental navigation, creation of editable sound sources (audio properties, movement and triggering events) and real-time playback/recording of the soundscape. Additionally, there are two available camera angles in development, the default being the player view and the alternative an up-view.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{immerscape}
  \caption{Immerscape's environment, through the player view perspective. The red cube represents an audio object (Reproduced from~\cite{ferreira2021creating}). \copyright~2021 Carolina Ribeiro Dias Ferreira.}
  \label{fig:immerscape-img}
\end{figure}

An evaluation with 10 developer and 7 non-developer participants highlighted Immerscape’s high usability and immersive quality.
It is one of many examples where spatialized audio with the HRTF technique was proven to be an effective way of providing engaging sonic experiences, in this case by immersively conveying historical soundscapes. 

While Ferreira’s work targets general audiences rather than the BVI demographic, there is much to take away from it in the context of this dissertation.
Immerscape’s design as well as its implementation of the HRTF filters is undoubtebly an inspiration to what will transpire over the course of our work, particularly regarding spatial audio simulation and ease of use for non-experienced users. Furthermore, some of the requirements defined by Ferreira including predefined 3D sound environments, editable audio sources and real-time playback of the scene are likely to be imported over to our research, aligning with our goal of creating an intuitive yet expressive soundscape editor.




\subsection{Design Space Considerations}

\section{Concluding Remarks}

Objective: Provide a synthesis of the reviewed work, highlighting gaps and considerations relevant to your proposed solution.

Topics to Include:
Key limitations of existing immersive audio systems and accessibility efforts.
Opportunities for innovation in soundscape design and spatial audio accessibility.
Final considerations for designing a tool that balances accessibility, interactivity, and usability for both creators and BVI users.

Link to Dissertation: Summarize how your proposed solution builds upon and addresses the shortcomings identified in prior research.