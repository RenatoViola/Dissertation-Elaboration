% Encoding: UTF-8

%intro_begin
@online{five-senses,
    url = {https://dana.org/resources/the-senses-vision/},
    urldate = {2024-12-23},
    keywords = {senses,vision,sight},
    title = {The Senses: Vision},
}

@online{vision-is-dominant-sense,
    url = {https://www.newjerseyeyesite.com/vision-therapy-optometrist/the-17-visual-skills-assessed-during-your-childs-functional-eye-exam/vision-our-dominant-sense/#:~:text=Vision%20is%20our%20dominant%20sense&text=It%20is%20a%20complex%2C%20learned,activities%20are%20mediated%20through%20vision},
    urldate = {2024-12-23},
    keywords = {senses,vision,sight,dominant},
    title = {Vision: Our dominant Sense},
}

@online{sight-is-most-important-sense-1,
  url = {https://assilaye.com/blog/is-sight-the-most-important-sense/},
  urldate = {2024-12-23},
  keywords = {senses, vision, sight, important},
  title = {77\% of People Say Sight is Their Most Important Sense}
}


@article{sight-is-most-important-sense-2,
    author = {Enoch, Jamie and McDonald, Leanne and Jones, Lee and Jones, Pete R. and Crabb, David P.},
    title = {Evaluating Whether Sight Is the Most Valued Sense},
    journal = {JAMA Ophthalmology},
    volume = {137},
    number = {11},
    pages = {1317-1320},
    year = {2019},
    month = {11},
    issn = {2168-6165},
    doi = {10.1001/jamaophthalmol.2019.3537},
    url = {https://doi.org/10.1001/jamaophthalmol.2019.3537},
    eprint = {https://jamanetwork.com/journals/jamaophthalmology/articlepdf/2752217/jamaophthalmology\_enoch\_2019\_br\_190017.pdf},
}

@online{global-estimates-of-vision-loss,
    url = {https://www.iapb.org/learn/vision-atlas/magnitude-and-projections/global/},
    urldate = {2024-12-23},
    keywords = {vision,global},
    title = {Global Estimates of Vision Loss},
}

@online{vision-loss-projections-2020-2050,
    url = {https://www.iapb.org/learn/vision-atlas/magnitude-and-projections/projected-change/},
    urldate = {2024-12-23},
    keywords = {global,vision,sight,projections},
    title = {Projected Change in Vision Loss 2020 to 2050},
}

@online{crpd-rights,
    url = {https://social.desa.un.org/issues/disability/crpd/convention-on-the-rights-of-persons-with-disabilities-crpd},
    urldate = {2024-12-23},
    keywords = {rights,vision,sight,legal},
    title = {Convention on the Rights of Persons with Disabilities (CRPD)},
}

@online{who-vision-impairment,
    url = {https://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment},
    urldate = {2024-12-23},
    keywords = {vision,sight},
    title = {Blindness and vision impairment},
}
%intro_end

%motivation_begin
@article{cavazos2021accessible,
  title={Accessible visual artworks for blind and visually impaired people: comparing a multimodal approach with tactile graphics},
  author={Cavazos Quero, Luis and Iranzo Bartolom{\'e}, Jorge and Cho, Jundong},
  journal={Electronics},
  volume={10},
  number={3},
  pages={297},
  year={2021},
  publisher={MDPI}
}

@inproceedings{li2023understanding,
  title={Understanding visual arts experiences of blind people},
  author={Li, Franklin Mingzhe and Zhang, Lotus and Bandukda, Maryam and Stangl, Abigale and Shinohara, Kristen and Findlater, Leah and Carrington, Patrick},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2023}
}

@article{vasilakou2022accessibility,
  title={The accessibility of visually impaired people to museums and art through ICTs},
  author={Vasilakou, Paraskevi and Mineiko, Sofia and Hasioti, Theopisti Marina and Gavriilidou, Zoe and Drigas, Athanasios},
  journal={Technium Soc. Sci. J.},
  volume={35},
  pages={263},
  year={2022},
  publisher={HeinOnline}
}

@article{vaz2020blind,
  title={Blind and visually impaired visitors’ experiences in museums: increasing accessibility through assistive technologies},
  author={Vaz, Roberto and Freitas, Diamantino and Coelho, Ant{\'o}nio},
  journal={The International Journal of the Inclusive Museum},
  volume={13},
  number={2},
  pages={57},
  year={2020},
  publisher={Common Ground Research Networks}
}

@inproceedings{vaz2020perspectives,
  title={Perspectives of visually impaired visitors on museums: towards an integrative and multisensory framework to enhance the museum experience},
  author={Vaz, Roberto and Freitas, Diamantino and Coelho, Ant{\'o}nio},
  booktitle={Proceedings of the 9th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion},
  pages={17--21},
  year={2020}
}

@inproceedings{holloway2019making,
  title={Making sense of art: Access for gallery visitors with vision impairments},
  author={Holloway, Leona and Marriott, Kim and Butler, Matthew and Borning, Alan},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2019}
}

@article{martins2020blindness,
  title={Blindness in art museums: A Portuguese case study},
  author={Martins, Patr{\'\i}cia Roque},
  journal={Journal of museum education},
  volume={45},
  number={3},
  pages={340--349},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{rector2017eyes,
  title={Eyes-free art: Exploring proxemic audio interfaces for blind and low vision art engagement},
  author={Rector, Kyle and Salmon, Keith and Thornton, Dan and Joshi, Neel and Morris, Meredith Ringel},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={1},
  number={3},
  pages={1--21},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{candlin2003blindness,
  title={Blindness, art and exclusion in museums and galleries},
  author={Candlin, Fiona},
  journal={International Journal of Art \& Design Education},
  volume={22},
  number={1},
  pages={100--110},
  year={2003},
  publisher={Wiley Online Library}
}

@article{krol2024design,
  title={Design Considerations for Automatic Musical Soundscapes of Visual Art for People with Blindness or Low Vision},
  author={Krol, Stephen James and Llano, Maria Teresa and Butler, Matthew and Goncu, Cagatay},
  journal={arXiv preprint arXiv:2405.14188},
  year={2024}
}

@inproceedings{asakawa2019independent,
  title={An independent and interactive museum experience for blind people},
  author={Asakawa, Saki and Guerreiro, Jo{\~a}o and Sato, Daisuke and Takagi, Hironobu and Ahmetovic, Dragan and Gonzalez, Desi and Kitani, Kris M and Asakawa, Chieko},
  booktitle={Proceedings of the 16th International Web for All Conference},
  pages={1--9},
  year={2019}
}

@article{chang2024sound,
  title={Sound Unblending: Exploring Sound Manipulations for Accessible Mixed-Reality Awareness},
  author={Chang, Ruei-Che and Hung, Chia-Sheng and Chen, Bing-Yu and Jain, Dhruv and Guo, Anhong},
  journal={arXiv preprint arXiv:2401.11095},
  year={2024}
}

@article{li2024beyond,
  title={Beyond Sight: Enhancing Augmented Reality Interactivity with Audio-Based and Non-Visual Interfaces},
  author={Li, Jingya},
  journal={Applied Sciences},
  volume={14},
  number={11},
  pages={4881},
  year={2024},
  publisher={MDPI}
}

@inproceedings{yang2019audio,
  title={Audio-augmented museum experiences with gaze tracking},
  author={Yang, Jing and Chan, Cheuk Yu},
  booktitle={Proceedings of the 18th international conference on mobile and ubiquitous multimedia},
  pages={1--5},
  year={2019}
}

@inproceedings{sanchez2007usability,
  title={Usability of Audio-Based Virtual Environments for Users with Visual Disabilities},
  author={S{\'a}nchez, Jaime and S{\'a}enz, Mauricio},
  booktitle={Virtual Reality and Human Behavior Symposium, LAVAL Virtual},
  pages={18--22},
  year={2007}
}

@online{how-museums-remove-barriers-for-bvi,
    url = {https://www.museumnext.com/article/how-museums-can-remove-barriers-to-access-for-blind-and-partially-sighted-people/},
    urldate = {2024-12-23},
    keywords = {museums,accessibility,bvi},
    title = {How museums can remove barriers to access for blind and partially sighted people},
}

@online{virtual-space-accessibility,
    url = {https://www.1854.photography/2021/06/the-future-of-art-spaces-how-accessible-is-the-virtual-space/},
    urldate = {2024-12-23},
    keywords = {virtual,accessibility},
    title = {The future of art spaces: How accessible is the virtual space?},
}

@online{smartphone-stats,
    url = {https://www.demandsage.com/smartphone-users/},
    urldate = {2024-12-23},
    keywords = {stats,smartphone},
    title = {How Many People Own Smartphones (2024): Worldwide Data},
}

@online{smartphone-features,
    url = {https://www.aarp.org/home-family/personal-technology/info-2020/smartphone-accessibility.html},
    urldate = {2024-12-23},
    keywords = {features,smartphone},
    title = {Accessibility Settings, Tools on Your Smartphone Can Make Life Easier},
}
%motivation_end

% background_begin

@article{fundamentals-of-hearing-w-yost,
author = {Yost, William and Schlauch, Robert},
year = {2001},
month = {10},
pages = {},
title = {Fundamentals of Hearing: An Introduction (4th edition)},
volume = {110},
journal = {Journal of The Acoustical Society of America - J ACOUST SOC AMER},
doi = {10.1121/1.1398047}
}

@book{spatial-audio-f-rumsey,
author = {Rumsey, Francis},
year = {2001},
month = {01},
pages = {},
title = {Spatial Audio},
isbn = {9780080498195},
doi = {10.4324/9780080498195}
}

@article{risoud2018sound,
  title={Sound source localization},
  author={Risoud, Michael and Hanson, J-N and Gauvrit, Fanny and Renard, Christian and Lemesre, P-E and Bonne, N-X and Vincent, Christophe},
  journal={European annals of otorhinolaryngology, head and neck diseases},
  volume={135},
  number={4},
  pages={259--264},
  year={2018},
  publisher={Elsevier}
}

@book{schafer1993soundscape,
  title={The soundscape: Our sonic environment and the tuning of the world},
  author={Schafer, R Murray},
  year={1993},
  publisher={Simon and Schuster}
}

@article{aletta2016soundscape,
  title={Soundscape descriptors and a conceptual framework for developing predictive soundscape models},
  author={Aletta, Francesco and Kang, Jian and Axelsson, {\"O}sten},
  journal={Landscape and Urban Planning},
  volume={149},
  pages={65--74},
  year={2016},
  publisher={Elsevier}
}

@article{dumyahn2011soundscape,
  title={Soundscape conservation},
  author={Dumyahn, Sarah L and Pijanowski, Bryan C},
  journal={Landscape ecology},
  volume={26},
  pages={1327--1344},
  year={2011},
  publisher={Springer}
}

@article{brown2011towards,
  title={Towards standardization in soundscape preference assessment},
  author={Brown, Alan Lex and Kang, Jian and Gjestland, Truls},
  journal={Applied acoustics},
  volume={72},
  number={6},
  pages={387--392},
  year={2011},
  publisher={Elsevier}
}

@inproceedings{rychtarikova2012towards,
  title={Towards more inclusive approaches in soundscape research: The soundscape of blind people},
  author={Rycht{\'a}rikov{\'a}, Monika and Herssens, Jasmien and Heylighen, Ann},
  booktitle={Inter-noise and noise-con congress and conference proceedings},
  year={2012},
  organization={Institute of Noise Control Engineering New York}
}

% background_end

% images_begin

@online{sinusoid-img,
    url = {http://www.billavista.com/atv/Articles/Offroad_Radios_and_Comms/index.html},
    urldate = {2025-01-04},
    keywords = {sinusoid,simple},
    title = {Two-way Radio Basic Theory - By Bill "BillaVista" Ansell},
}

@online{pressure-zones-img,
    url = {https://beccasaville.blogspot.com/2012/09/compression-and-rarefaction.html},
    urldate = {2025-01-04},
    keywords = {sinusoid,pressure,rarefaction,condensation},
    title = {Audio, Image and Video Processing},
}

@article{spatial-dimensions-img,
title = {Sound source localization},
journal = {European Annals of Otorhinolaryngology, Head and Neck Diseases},
volume = {135},
number = {4},
pages = {259-264},
year = {2018},
issn = {1879-7296},
doi = {https://doi.org/10.1016/j.anorl.2018.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S187972961830067X},
author = {M. Risoud and J.-N. Hanson and F. Gauvrit and C. Renard and P.-E. Lemesre and N.-X. Bonne and C. Vincent},
keywords = {Sound source localization, Interaural time difference, Interaural level difference, Head-related transfer function},
abstract = {Sound source localization is paramount for comfort of life, determining the position of a sound source in 3 dimensions: azimuth, height and distance. It is based on 3 types of cue: 2 binaural (interaural time difference and interaural level difference) and 1 monaural spectral cue (head-related transfer function). These are complementary and vary according to the acoustic characteristics of the incident sound. The objective of this report is to update the current state of knowledge on the physical basis of spatial sound localization.}
}

@article{interaural-differences-img,
author = {Zhong, Xuan and Yost, William and Sun, Liang},
year = {2015},
month = {04},
pages = {2376-2376},
title = {Dynamic binaural sound source localization with ITD cues: Human listeners},
volume = {137},
journal = {Journal of the Acoustical Society of America},
doi = {10.1121/1.4920636}
}

@article{cone-of-confusion-img,
author = {McMullen, Kyla},
year = {2012},
month = {01},
pages = {},
title = {Interface Design Implications for Recalling the Spatial Configuration of Virtual Auditory Environments.}
}

@article{hrtf-img,
title = {Compensating first reflections in non-anechoic head-related transfer function measurements},
journal = {Applied Acoustics},
volume = {188},
pages = {108523},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108523},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21006174},
author = {Jose J. Lopez and Pablo Gutierrez-Parera and Maximo Cobos},
keywords = {HRTF, Acoustic channel measurement, Echo removal, Plane wave decomposition, Spherical arrays, Spatial audio},
abstract = {Personalized Head-Related Transfer Functions (HRTFs) are needed as part of the binaural sound individualization process in order to provide a high-quality immersive experience for a specific user. Signal processing methods for performing HRTF measurements in non-anechoic conditions are of high interest to avoid the complex and inconvenient access to anechoic facilities. Non-anechoic HRTF measurements capture the effect of room reflections, which should be correctly identified and eliminated to obtain HRTFs estimates comparable to ones acquired in an anechoic setup. This paper proposes a sub-band frequency-dependent processing method for reflection suppression in non-anechoic HRTF signals. Array processing techniques based on Plane Wave Decomposition (PWD) are adopted as an essential part of the solution for low frequency ranges, whereas the higher frequencies are easily handled by means of time-crop windowing methods. The formulation of the model, extraction of parameters and evaluation of the method are described in detail. In addition, a validation case study is presented showing the suppression of reflections from an HRTF measured in a real system. The results confirm that the method allows to obtain processed HRTFs comparable to those acquired in anechoic conditions.}
}
% images_end

%% related work begin

@article{fartaria2013navmol,
  title={NavMol 2.0--a molecular structure navigator/editor for blind and visually impaired users},
  author={Fartaria, Rui PS and Pereira, Florbela and Bonif{\'a}cio, Vasco DB and Mata, Paulina and Aires-de-Sousa, Jo{\~a}o and Lobo, Ana M},
  journal={European journal of organic chemistry},
  volume={2013},
  number={8},
  pages={1415--1419},
  year={2013},
  publisher={Wiley Online Library}
}

@misc{rodrigues2015navmol,
   author = {Ian Nunes Rodrigues and Sofia Cavaco and Professora Auxiliar and João Aires De Sousa and Júri Presidente and : Doutor and Vitor Manuel and Alves Duarte and Arguente : Doutor and Daniel Jorge and Viegas Gonçalves and Vogal : Doutora and Sofia Carmen and Faria Cavaco},
   title = {Espacialização de Som no Navegador e Editor Molecular Navmol Dissertação para obtenção do Grau de Mestre em Engenharia Informática},
   url = {https://github.com/joaomlourenco/unlthesis},
}



%% related work end